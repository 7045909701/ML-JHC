{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b13e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387e6955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219289</th>\n",
       "      <td>Other Software Projects Are Now Trying to Repl...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219290</th>\n",
       "      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219291</th>\n",
       "      <td>chatgpt is being disassembled until it can onl...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219292</th>\n",
       "      <td>2023 predictions by #chatGPT. Nothing really s...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219293</th>\n",
       "      <td>From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219294 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets   labels\n",
       "0       ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
       "1       Try talking with ChatGPT, our new AI system wh...     good\n",
       "2       ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
       "3       THRILLED to share that ChatGPT, our new model ...     good\n",
       "4       As of 2 minutes ago, @OpenAI released their ne...      bad\n",
       "...                                                   ...      ...\n",
       "219289  Other Software Projects Are Now Trying to Repl...      bad\n",
       "219290  I asked #ChatGPT to write a #NYE Joke for SEOs...     good\n",
       "219291  chatgpt is being disassembled until it can onl...      bad\n",
       "219292  2023 predictions by #chatGPT. Nothing really s...      bad\n",
       "219293   From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0  neutral\n",
       "\n",
       "[219294 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('file.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bcb3399",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2856dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca9320de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(binary = True)\n",
    "vectorizer2 = CountVectorizer(binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378c78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = vectorizer1.fit_transform(df.tweets)\n",
    "x2 = vectorizer2.fit_transform(df.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518c6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    " y = df.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2368ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain1,xtest1,ytrain,ytest=train_test_split(x1,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e5d43f8",
   "metadata": {},
   "outputs": [],
   "source": [
    " xtrain2,xtest2,ytrain,ytest = train_test_split(x2,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d795c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "644f44c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(xtrain1,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea0ad2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(xtrain2,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a118d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bnb.predict(xtest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0c6fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = mnb.predict(xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c9ebc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b674cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6216255654457902"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a27937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7144681161535094"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a1253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5850065",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = TfidfVectorizer(binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaeabf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = vector1.fit_transform(df.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c3a3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1f9ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain2,xtest2,ytrain,ytest = train_test_split(x3,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16fd684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "266e8de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(xtrain2,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a72ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = mnb.predict(xtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63f850a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4710fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7238435721581788"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64912fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conclusion:: The above data shows better accuracy score for MultinomialNB Model with frequency based vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31ca39f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC-19\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Binary-based Vectors is 0.6446811615350941\n",
      "Accuracy score for Frequency-based vectors is 0.7238435721581788\n",
      "Accuracy score for tfidf score based vectors is 0.6569750474244856\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "df['tweets'] = df['tweets'].apply(remove_stopwords)\n",
    "x=df.iloc[:,0]\n",
    "y=df.iloc[:,1]\n",
    "x1=vectorizer1.fit_transform(x)\n",
    "x2=vectorizer2.fit_transform(x)\n",
    "x3=vector1.fit_transform(x)\n",
    "xtrain1,xtest1,ytrain,ytest=train_test_split(x1,y,test_size=0.25,random_state=1)\n",
    "xtrain2,xtest2,ytrain,ytest=train_test_split(x2,y,test_size=0.25,random_state=1)\n",
    "xtrain3,xtest3,ytrain,ytest=train_test_split(x3,y,test_size=0.25,random_state=1)\n",
    "bnb.fit(xtrain1,ytrain)\n",
    "mnb.fit(xtrain2,ytrain)\n",
    "mnb2.fit(xtrain3,ytrain)\n",
    "pred1=bnb.predict(xtest1)\n",
    "pred2=mnb.predict(xtest2)\n",
    "pred3=mnb2.predict(xtest3)\n",
    "print('Accuracy score for Binary-based Vectors is',accuracy_score(pred1,ytest))\n",
    "print('Accuracy score for Frequency-based vectors is',accuracy_score(pred2,ytest))\n",
    "print('Accuracy score for tfidf score based vectors is',accuracy_score(pred3,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba87e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conclusion- The above data shows better accuracy score for MultinomialNB Model with frequency based vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
